# web\u7AEF\u53E3
server.port=8080

# \u8BBE\u7F6E\u9ED8\u8BA4\u7F16\u7801
spring.messages.encoding=UTF-8
server.servlet.encoding.charset=UTF-8
server.servlet.encoding.enabled=true
server.servlet.encoding.force=true

#langchain4j\u6D4B\u8BD5\u6A21\u578B
#langchain4j.open-ai.chat-model.base-url=http://langchain4j.dev/demo/openai/v1
#langchain4j.open-ai.chat-model.api-key=demo
#langchain4j.open-ai.chat-model.model-name=gpt-4o-mini

#DeepSeek
langchain4j.open-ai.chat-model.base-url=https://dashscope.aliyuncs.com/compatible-mode/v1
langchain4j.open-ai.chat-model.api-key=${DASHSCOPE_API_KEY}
#DeepSeek-V3
langchain4j.open-ai.chat-model.model-name=deepseek-v3
#DeepSeek-R1 \u6A21\u578B
#langchain4j.open-ai.chat-model.model-name=deepseek-reasoner

#???????
langchain4j.open-ai.chat-model.log-requests=true
langchain4j.open-ai.chat-model.log-responses=true

#ollama
langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.model-name=deepseek-r1:1.5b
langchain4j.ollama.chat-model.temperature=0.8
langchain4j.ollama.chat-model.timeout=PT60S
#\u8BF7\u6C42\u548C\u54CD\u5E94\u65E5\u5FD7
langchain4j.ollama.chat-model.log-requests=true
langchain4j.ollama.chat-model.log-responses=true


#\u963F\u91CC\u767E\u70BC\u5E73\u53F0
langchain4j.community.dashscope.chat-model.api-key=${DASHSCOPE_API_KEY}
langchain4j.community.dashscope.chat-model.model-name=qwen-max



#MongoDB\u8FDE\u63A5\u914D\u7F6E
spring.data.mongodb.uri=mongodb://localhost:27017/chat_memory_db

#\u542F\u7528\u65E5\u5FD7debug\u7EA7\u522B
#logging.level.root=debug

